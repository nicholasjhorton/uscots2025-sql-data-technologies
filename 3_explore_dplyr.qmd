---
title: "Explore the airlines data using dplyr and sql chunks"
subtitle: "USCOTS 2025 breakout session"
author: "Nicholas Horton (nhorton@amherst.edu) and Jo Hardin (jo.hardin@pomona.edu)"
date: "2025-07-18"
date-format: long
format: pdf
execute:
  warning: false
  message: false
toc: true
editor: source
---

```{r}
#| label: setup
#| include: false
library(tidyverse)
library(duckdb)
library(DBI)
library(arrow)
rnd_val <- 2
```

## Introduction

The current Quarto file analyzes airline flight data from the [American Statistical Association's Data Expo 2024](https://community.amstat.org/dataexpo/home).
Once the `1_download_data.qmd` Quarto file has been successfully rendered, you should be able to render the current file (`3_explore_dplyr.qmd`) which shows off **dplyr** syntax and `sql` chunks while analyzing the downloaded data.

See https://community.amstat.org/dataexpo/home for more information on the data.

See https://beanumber.github.io/abdwr3e/12-large.html and https://mdsr-book.github.io/mdsr3e/15-sqlI.html for resources on databases in R.

See https://hardin47.netlify.app/courses/sds261-sql/ for an accessible overview of SQL and databases.

## Check for files

First we check that the files are where we expect.
If you run the code below with no errors, you are ready to go!
(If you run into problems, try rendering the file or "Change Working Directory" to "File Location" under the "Session" Menu in RStudio.

```{r}
folder_name <- "data_airlines"
stopifnot(file.exists(folder_name))
stopifnot(file.exists(paste0(folder_name, "/Year=2024/data_0.parquet")))
```

## Check reading via DuckDb

We begin by creating an in-memory database using DuckDb, which is just a placeholder that we can reference.

```{r}
con_duckdb <- DBI::dbConnect(duckdb::duckdb())
```

# Accessing databases using **dplyr**

Here we use a `tbl` (like a `tibble`, but it lives remotely) to create a shadow data frame from which we can query using **dplyr** wrangling verbs.
Note that the work done on the `tbl` **feels** just like working on a `tibble`, but the `tbl` object does not live in your local R environment.

```{r}
#| label: sizes

flights_duckdb <- tbl(
  con_duckdb, 
  paste0("read_parquet('", folder_name, "/Year*/*.parquet')"))

# size of pointer:
object.size(flights_duckdb |> filter(Year == 2024, Month == 3))

# size if you collect the object:
object.size(flights_duckdb |> filter(Year == 2024, Month == 3) |> collect())
```

## Which destinations are most delayed?

The following query uses the `flights_duckdb` object to group by destination and summarize the number of flights and average arrival delay.

```{r}
#| label: top_desk

delayedflights <- flights_duckdb |>
  group_by(Dest) |>
  summarise(n = n(), 
            avg_delay = mean(ArrDelay, na.rm = TRUE), 
            .groups = "drop") |>
  arrange(desc(avg_delay)) |>
  head(10)

delayedflights
show_query(delayedflights)

```

We note that the largest delays tend to be for airports that have relatively few flights (e.g., `HOB` is Lea County Regional Airport near Hobbs, Nevada, [Wikipedia](https://en.wikipedia.org/wiki/Lea_County_Regional_Airport)).
An exception is Orlando Airport (`SFB`, https://flysfb.com), which has a large number of flights and relatively large average delay.

## How many flights are there each month?

```{r}
#| label: bymonthyear2

aggregation_query <- flights_duckdb |>
  filter(Month %in% c(1,2,3,4,5)) |> 
  group_by(Month, Year) |>
  summarise(
    n = n(), 
    avg_delay = mean(ArrDelay, na.rm = TRUE), 
    .groups = "drop"
  ) |>
  arrange(Year, Month) 

aggregation_query
show_query(aggregation_query) 
```

Even though the `tbl` (and the results from the SQL query) are remote objects that do not live in your environment, you can use them as if they were local, for example, by inputting the `tbl` into a ggplot.
Here we both run the query and provide the translation to the underlying SQL call (see `2_explore_sql.qmd` for more SQL examples).

```{r}
flights_duckdb |>
  filter(Month %in% c(1,2,3,4,5)) |> 
  group_by(Month, Year) |>
  summarise(
    n = n(), 
    avg_delay = mean(ArrDelay, na.rm = TRUE), 
    .groups = "drop"
  ) |>
  arrange(Year, Month) |> 
  ggplot(aes(x = Month, y = avg_delay, color = as.factor(Year))) + 
  labs(
    title = "Average delay for arriving flights by Month and Year",
    x = "Month",
    y = "Average flight delay (in minutes)",
    color = "Year"
  ) +
  geom_point(size = 2) + 
  geom_line()
```

## Extension in dplyr

Use the following code chunk to answer your own question about the data using the `dplyr` interface.

```{r}

```


# Accessing databases using SQL chunks

## Which destinations are most delayed?

We can re-use the SQL code that was translated from **dplyr**! (We don't need two `FROM` commands, but that is a conversation for a different day... or ask us!)

```{sql}
#| connection: con_duckdb

SELECT Dest, COUNT(*) AS n, AVG(ArrDelay) AS avg_delay
FROM read_parquet('data_airlines/Year*/*.parquet')
GROUP BY Dest
ORDER BY avg_delay DESC
LIMIT 10;
```


## How many flights are there each month?

First, we'll re-use the SQL code that was translated from **dplyr**.

```{sql}
#| connection: con_duckdb

SELECT Month, Year, COUNT(*) AS n, AVG(ArrDelay) AS avg_delay
FROM (
  SELECT q01.*
  FROM (FROM read_parquet('data_airlines/Year*/*.parquet')) q01
  WHERE (Month IN (1.0, 2.0, 3.0, 4.0, 5.0))
) q01

GROUP BY Month, Year
ORDER BY Year, Month
```

But there really isn't any need to do the nested `SELECT` & `FROM`. We could write more succinct SQL code that does the same thing.

```{sql}
#| connection: con_duckdb

SELECT Month, Year, COUNT(*) AS n, AVG(ArrDelay) AS avg_delay
FROM read_parquet('data_airlines/Year*/*.parquet')
WHERE (Month IN (1.0, 2.0, 3.0, 4.0, 5.0))
GROUP BY Month, Year
ORDER BY Year, Month
```


## Extension in SQL

Use the following code chunk to answer your own question about the data using a `sql` chunk.  (Also, change the other argument to `eval: true`.)

```{sql}
#| connection: con_duckdb
#| eval: false


```



## From SQL to R

But if you use a `sql` chunk, how can you plot the data? Within the `sql` chunk, add an argument specifying the name of the (local!) dataframewhich will be created from the SQL query. Note that ggplot above is plotting `flights_duckdb` (which is a `tbl` that lives on the hard drive) and here we are plotting `flights_from_sql` (which is a `tibble` that lives in RAM).

```{sql}
#| connection: con_duckdb
#| output.var: "flights_from_sql"

SELECT Month, Year, COUNT(*) AS n, AVG(ArrDelay) AS avg_delay
FROM read_parquet('data_airlines/Year*/*.parquet')
WHERE (Month IN (1.0, 2.0, 3.0, 4.0, 5.0))
GROUP BY Month, Year
ORDER BY Year, Month
```


```{r}
flights_from_sql |>
  ggplot(aes(x = Month, y = avg_delay, color = as.factor(Year))) + 
  labs(
    title = "Average delay for arriving flights by Month and Year",
    x = "Month",
    y = "Average flight delay (in minutes)",
    color = "Year"
  ) +
  geom_point(size = 2) + 
  geom_line()
```

## Closing the SQL connection

It is always good practice to close your connection when you are through with it (particularly important if you are accessing a remote database).

```{r}
DBI::dbDisconnect(con_duckdb)
```
